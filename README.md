# Sistema de Reconhecimento de Categoria de Roupas para Pessoas com DeficiÃªncia Visual

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa um sistema de classificaÃ§Ã£o de imagens usando Deep Learning para auxiliar pessoas com deficiÃªncia visual a identificar categorias de roupas. O sistema utiliza Transfer Learning com 4 arquiteturas de redes neurais convolucionais (CNNs) prÃ©-treinadas, comparando seu desempenho e otimizando o melhor modelo encontrado.

### MotivaÃ§Ã£o

A ideia surgiu a partir da participaÃ§Ã£o no curso "Recursos Educacionais AcessÃ­veis para o Ensino e Aprendizagem de CiÃªncias da Natureza e MatemÃ¡tica para Estudantes com DeficiÃªncia Visual" (Instituto Benjamin Constant/MEC, 2023) e foi inspirada por relatos de pessoas com deficiÃªncia visual sobre os desafios cotidianos, como escolher roupas adequadas.

## ğŸ¯ Objetivos

- **Objetivo Principal**: Classificar imagens de roupas em 17 categorias (Blouses_Shirts, Dresses, Sweaters, Jackets_Coats, etc.)
- **Modelos Avaliados**: GoogLeNet, ResNet-50, MobileNet-v2, EfficientNet-B0
- **Abordagem**: Transfer Learning com modelos prÃ©-treinados no ImageNet
- **OtimizaÃ§Ã£o**: Fine-tuning do melhor modelo com tÃ©cnicas avanÃ§adas de regularizaÃ§Ã£o

## ğŸ“¦ Resumo do Escopo EntregÃ¡vel

**Fase Atual do Projeto**: Esta etapa concentrou-se estritamente na validaÃ§Ã£o da arquitetura de **ClassificaÃ§Ã£o de Categoria de Roupas (Single-Label)**, priorizando a obtenÃ§Ã£o de um baseline robusto e otimizado. A abordagem metodolÃ³gica incluiu:

- âœ… ComparaÃ§Ã£o sistemÃ¡tica de 4 arquiteturas de deep learning
- âœ… AvaliaÃ§Ã£o rigorosa com mÃºltiplas mÃ©tricas (Accuracy, Precision, Recall, F1-Score)
- âœ… OtimizaÃ§Ã£o do melhor modelo com tÃ©cnicas conservadoras de fine-tuning
- âœ… DocumentaÃ§Ã£o completa com visualizaÃ§Ãµes e relatÃ³rios exportÃ¡veis

**ClassificaÃ§Ã£o Multi-Label (Roupas + Cores)**: Embora seja o objetivo final do projeto para maximizar a utilidade prÃ¡tica do sistema, a classificaÃ§Ã£o simultÃ¢nea de categoria e cor foi estrategicamente adiada para trabalhos futuros. Esta decisÃ£o metodolÃ³gica permitiu:

1. Estabelecer um baseline sÃ³lido e validado para a tarefa de classificaÃ§Ã£o de categorias
2. Otimizar recursos computacionais e tempo de desenvolvimento dentro das restriÃ§Ãµes do prazo acadÃªmico
3. Garantir a qualidade e reprodutibilidade dos resultados apresentados
4. Criar uma base tÃ©cnica robusta para expansÃ£o futura do sistema

**SaÃ­das Geradas**: Todos os resultados sÃ£o automaticamente salvos em mÃºltiplos formatos:
- ğŸ“Š **Imagens**: GrÃ¡ficos de distribuiÃ§Ã£o, histÃ³ricos de treinamento, matrizes de confusÃ£o
- ğŸ“„ **Arquivos TXT**: RelatÃ³rios detalhados de cada etapa do processamento
- ğŸ“‹ **Arquivo JSON**: MÃ©tricas baseline para comparaÃ§Ã£o automÃ¡tica
- ğŸ“¦ **Arquivo ZIP**: Pacote completo com todos os resultados para download (gerado automaticamente ao final da execuÃ§Ã£o)

## ğŸ“š ReferÃªncias

**Artigo Base**: "Blind People: Clothing Category Classification and Stain Detection Using Transfer Learning" (2023)
- DOI: https://doi.org/10.3390/app13031925
- Melhor modelo no artigo: GoogLeNet

## ğŸ—‚ï¸ Estrutura do Projeto

scripts/
â”œâ”€â”€ 01_preparacao_dados.py       # Download, exploraÃ§Ã£o e visualizaÃ§Ã£o do dataset
â”œâ”€â”€ 02_preprocessamento.py       # TransformaÃ§Ãµes, data augmentation e dataloaders
â”œâ”€â”€ 03_modelos.py                # DefiniÃ§Ã£o dos quatro modelos com transfer learning
â”œâ”€â”€ 04_treinamento.py            # FunÃ§Ãµes de treinamento com early stopping
â”œâ”€â”€ 05_avaliacao.py              # MÃ©tricas, visualizaÃ§Ãµes e relatÃ³rios
â”œâ”€â”€ 06_execucao_principal.py     # Pipeline completo de treinamento baseline
â”œâ”€â”€ 07_otimizacao_modelo.py      # OtimizaÃ§Ã£o do melhor modelo (EfficientNet-B0)
â””â”€â”€ 08_exportacao_resultados.py  # ExportaÃ§Ã£o de todos os resultados em arquivo ZIP

## ğŸ“Š Dataset

**DeepFashion-1** (Kaggle)
- Link: https://www.kaggle.com/datasets/vishalbsadanand/deepfashion-1
- Total de imagens: 11.484
- NÃºmero de categorias: 17
- DivisÃ£o: 70% treino, 15% validaÃ§Ã£o, 15% teste

### Categorias de Roupas:

1. Blouses_Shirts (2.044 imagens - 17.80%)
2. Dresses (1.569 imagens - 13.66%)
3. Sweaters (1.359 imagens - 11.83%)
4. Jackets_Coats (1.149 imagens - 10.01%)
5. Tees_Tanks (1.149 imagens - 10.01%)
6. Shorts (840 imagens - 7.31%)
7. Skirts (735 imagens - 6.40%)
8. Cardigans (630 imagens - 5.49%)
9. Pants (525 imagens - 4.57%)
10. Rompers (420 imagens - 3.66%)
11. Jeans (315 imagens - 2.74%)
12. Graphic_Tees (315 imagens - 2.74%)
13. Sweatshirts (210 imagens - 1.83%)
14. Jackets_Vests (105 imagens - 0.91%)
15. Leggings (105 imagens - 0.91%)
16. Suiting (14 imagens - 0.12%)

### Como usar no Kaggle:

O dataset jÃ¡ estÃ¡ disponÃ­vel no Kaggle em `/kaggle/input/deepfashion-1/`. O script detecta automaticamente o ambiente e usa o caminho correto.

## ğŸš€ Como Executar

### No Kaggle Notebook (Recomendado):

1. **Crie um novo notebook no Kaggle**
2. **Adicione o dataset DeepFashion-1** ao notebook
3. **Copie cada script para uma cÃ©lula separada**
4. **Execute na ordem sequencial**:

\`\`\`python
# Bloco 1: PreparaÃ§Ã£o de Dados
%run scripts/01_preparacao_dados.py

# Bloco 2: PrÃ©-processamento
%run scripts/02_preprocessamento.py

# Bloco 3: DefiniÃ§Ã£o dos Modelos
%run scripts/03_modelos.py

# Bloco 4: FunÃ§Ãµes de Treinamento
%run scripts/04_treinamento.py

# Bloco 5: FunÃ§Ãµes de AvaliaÃ§Ã£o
%run scripts/05_avaliacao.py

# Bloco 6: Treinamento Baseline (4 modelos)
%run scripts/06_execucao_principal.py

# Bloco 7: OtimizaÃ§Ã£o do Melhor Modelo
%run scripts/07_otimizacao_modelo.py

# Bloco 8: ExportaÃ§Ã£o de Resultados em ZIP
%run scripts/08_exportacao_resultados.py
\`\`\`

### Tempo de ExecuÃ§Ã£o Estimado:

- **Bloco 1**: ~2 minutos (exploraÃ§Ã£o do dataset)
- **Bloco 2**: ~1 minuto (prÃ©-processamento)
- **Bloco 3**: ~30 segundos (definiÃ§Ã£o dos modelos)
- **Bloco 4-5**: InstantÃ¢neo (apenas definiÃ§Ãµes de funÃ§Ãµes)
- **Bloco 6**: ~2-3 horas (treinamento de 4 modelos com 10 Ã©pocas cada)
- **Bloco 7**: ~1-2 horas (otimizaÃ§Ã£o com 20 Ã©pocas)
- **Bloco 8**: ~30 segundos (exportaÃ§Ã£o do ZIP)

**Total**: ~4-6 horas no Kaggle com GPU T4

## ğŸ“ˆ MÃ©tricas Avaliadas

O projeto calcula e visualiza as seguintes mÃ©tricas para cada modelo:

- âœ… **Train Accuracy**: AcurÃ¡cia no conjunto de treinamento
- âœ… **Validation Accuracy**: AcurÃ¡cia no conjunto de validaÃ§Ã£o
- âœ… **Test Accuracy**: AcurÃ¡cia no conjunto de teste
- âœ… **Precision**: PrecisÃ£o das prediÃ§Ãµes positivas (macro-average)
- âœ… **Recall**: Taxa de verdadeiros positivos identificados (macro-average)
- âœ… **F1-Score**: MÃ©dia harmÃ´nica entre Precision e Recall (macro-average)
- âœ… **Overfitting**: DiferenÃ§a entre Train Accuracy e Test Accuracy
- âœ… **Matriz de ConfusÃ£o**: VisualizaÃ§Ã£o detalhada de acertos e erros por classe
- âœ… **F1-Score por Classe**: Desempenho individual em cada categoria de roupa

## ğŸ“Š Arquivos de SaÃ­da Gerados

### Bloco 1 - PreparaÃ§Ã£o de Dados:
- `bloco01_primeiras_10_imagens.png`: Amostra visual do dataset
- `bloco01_distribuicao_categorias.png`: GrÃ¡fico de distribuiÃ§Ã£o das 17 categorias
- `bloco01_saida.txt`: RelatÃ³rio com estatÃ­sticas do dataset

### Bloco 2 - PrÃ©-processamento:
- `bloco02_distribuicao_categorias.png`: DistribuiÃ§Ã£o apÃ³s prÃ©-processamento
- `bloco02_saida.txt`: RelatÃ³rio com divisÃ£o treino/val/teste e transformaÃ§Ãµes

### Bloco 6 - Treinamento Baseline:
- `bloco06_historico_googlenet.png`: Curvas de loss e acurÃ¡cia (GoogLeNet)
- `bloco06_historico_resnet50.png`: Curvas de loss e acurÃ¡cia (ResNet-50)
- `bloco06_historico_mobilenet_v2.png`: Curvas de loss e acurÃ¡cia (MobileNet-v2)
- `bloco06_historico_efficientnet_b0.png`: Curvas de loss e acurÃ¡cia (EfficientNet-B0)
- `bloco06_matriz_confusao_googlenet.png`: Matriz de confusÃ£o (GoogLeNet)
- `bloco06_matriz_confusao_resnet50.png`: Matriz de confusÃ£o (ResNet-50)
- `bloco06_matriz_confusao_mobilenet_v2.png`: Matriz de confusÃ£o (MobileNet-v2)
- `bloco06_matriz_confusao_efficientnet_b0.png`: Matriz de confusÃ£o (EfficientNet-B0)
- `bloco06_tabela_comparacao_modelos.png`: Tabela comparativa de desempenho
- `bloco06_baseline_metrics.json`: MÃ©tricas do melhor modelo (para comparaÃ§Ã£o automÃ¡tica)
- `bloco06_saida.txt`: RelatÃ³rio completo do treinamento baseline

### Bloco 7 - OtimizaÃ§Ã£o:
- `bloco07_historico_treinamento.png`: Curvas de loss e acurÃ¡cia da otimizaÃ§Ã£o
- `bloco07_matriz_confusao_otimizada.png`: Matriz de confusÃ£o do modelo otimizado
- `bloco07_f1_score_por_classe.png`: ComparaÃ§Ã£o de F1-Score por categoria
- `bloco07_tabela_comparacao_final.png`: Tabela comparativa (Original vs Otimizado vs TTA)
- `bloco07_saida.txt`: RelatÃ³rio completo da otimizaÃ§Ã£o

### Bloco 8 - ExportaÃ§Ã£o:
- `resultados_deepfashion_classificacao.zip`: Arquivo ZIP contendo todos os resultados acima

**Total**: 18 arquivos de imagem + 4 arquivos TXT + 1 arquivo JSON + 1 arquivo ZIP

## âš™ï¸ HiperparÃ¢metros

### Treinamento Baseline (Bloco 6):
\`\`\`python
BATCH_SIZE = 32
IMG_SIZE = 224
NUM_EPOCHS = 10
LEARNING_RATE = 0.001
OPTIMIZER = Adam
LOSS_FUNCTION = CrossEntropyLoss
TRAIN_SPLIT = 0.7   # 70% treino (8.038 imagens)
VAL_SPLIT = 0.15    # 15% validaÃ§Ã£o (1.722 imagens)
TEST_SPLIT = 0.15   # 15% teste (1.724 imagens)
\`\`\`

### OtimizaÃ§Ã£o (Bloco 7):
\`\`\`python
NUM_EPOCHS = 20
LEARNING_RATE = 0.0001  # Reduzido para fine-tuning
WEIGHT_DECAY = 0.0005   # RegularizaÃ§Ã£o L2
DROPOUT = 0.2           # Dropout no classificador
EARLY_STOPPING_PATIENCE = 7
LR_SCHEDULER = ReduceLROnPlateau (patience=3, factor=0.5)
CLASS_WEIGHTING = Inversamente proporcional Ã  frequÃªncia
TEST_TIME_AUGMENTATION = Horizontal Flip (mÃ©dia de 2 prediÃ§Ãµes)
\`\`\`

## ğŸ”§ Requisitos

\`\`\`python
# Deep Learning
torch >= 2.0.0
torchvision >= 0.15.0

# Processamento de Dados
numpy >= 1.24.0
pandas >= 2.0.0
Pillow >= 9.5.0

# VisualizaÃ§Ã£o
matplotlib >= 3.7.0
seaborn >= 0.12.0

# MÃ©tricas e Utilidades
scikit-learn >= 1.3.0
tqdm >= 4.65.0

# Dataset
kagglehub  # Para download automÃ¡tico do Kaggle
\`\`\`

**Nota**: Todos os requisitos jÃ¡ estÃ£o disponÃ­veis no ambiente Kaggle Notebooks.

## ğŸ“ Notas Importantes

1. **Recursos Computacionais**: O projeto foi otimizado para rodar no Kaggle com GPU T4 (16GB VRAM)
2. **Transfer Learning**: Todos os modelos usam pesos prÃ©-treinados do ImageNet
3. **Data Augmentation**: Aplicado apenas no conjunto de treinamento (rotaÃ§Ã£o, flip, crop, ajustes de cor)
4. **Reprodutibilidade**: Seeds fixadas (`torch.manual_seed(42)`) para resultados consistentes
5. **Class Weighting**: Pesos inversamente proporcionais Ã  frequÃªncia para lidar com desbalanceamento
6. **Early Stopping**: Implementado para prevenir overfitting (patience=5 no baseline, patience=7 na otimizaÃ§Ã£o)
7. **Nomenclatura de Arquivos**: Todos os arquivos tÃªm prefixo `blocoXX_` para evitar sobrescriÃ§Ã£o

## ğŸ“ Contexto AcadÃªmico

Este projeto foi desenvolvido como parte de uma disciplina de mestrado com os seguintes requisitos:

- âœ… Artigo de referÃªncia dos Ãºltimos 4 anos (2023)
- âœ… ComparaÃ§Ã£o de 4 modelos de deep learning (GoogLeNet, ResNet-50, MobileNet-v2, EfficientNet-B0)
- âœ… OtimizaÃ§Ã£o do melhor modelo encontrado (EfficientNet-B0)
- âœ… Uso de transfer learning com pesos prÃ©-treinados
- âœ… AvaliaÃ§Ã£o metodolÃ³gica rigorosa com mÃºltiplas mÃ©tricas
- âœ… DocumentaÃ§Ã£o completa com cÃ³digo comentado linha por linha em portuguÃªs
- âœ… VisualizaÃ§Ãµes e relatÃ³rios exportÃ¡veis

## ğŸ”¬ Metodologia de OtimizaÃ§Ã£o

A otimizaÃ§Ã£o do melhor modelo (EfficientNet-B0) seguiu uma abordagem conservadora e comprovada:

### TÃ©cnicas Aplicadas:

1. **Class Weighting**: Pesos inversamente proporcionais Ã  frequÃªncia das classes
2. **Learning Rate Reduzido**: 0.0001 (10x menor que o baseline)
3. **Weight Decay**: 0.0005 para regularizaÃ§Ã£o L2
4. **Dropout**: 0.2 no classificador final
5. **Learning Rate Scheduler**: ReduceLROnPlateau (reduz LR quando validaÃ§Ã£o estagna)
6. **Early Stopping**: Patience=7 para prevenir overfitting
7. **Test-Time Augmentation (TTA)**: Horizontal flip para melhorar prediÃ§Ãµes

### EstratÃ©gia de Fine-Tuning:

- **Fase Ãšnica**: Todas as camadas descongeladas desde o inÃ­cio
- **Learning Rate Baixo**: Preserva features prÃ©-treinadas do ImageNet
- **Treinamento Prolongado**: 20 Ã©pocas com early stopping

## ğŸ“Š Resultados Esperados

Com base em execuÃ§Ãµes anteriores, os resultados tÃ­picos sÃ£o:

### Baseline (Bloco 6):
- **GoogLeNet**: ~65-70% Test Accuracy
- **ResNet-50**: ~65-70% Test Accuracy
- **MobileNet-v2**: ~60-65% Test Accuracy
- **EfficientNet-B0**: ~68-72% Test Accuracy (melhor modelo)

### OtimizaÃ§Ã£o (Bloco 7):
- **Objetivo**: Melhorar F1-Score e reduzir overfitting
- **Resultado Esperado**: +1-3% Test Accuracy, +2-5% F1-Score

**Nota**: Os resultados podem variar devido Ã  aleatoriedade no treinamento, mesmo com seeds fixadas.

## ğŸ‘¥ Autor

PPGIA - 2025
Disciplina: Aprendizado Profundo para VisÃ£o Computacional
Discente: Jacqueline Navarro da Silva

## ğŸ“„ LicenÃ§a

Este projeto Ã© para fins educacionais e de pesquisa acadÃªmica.

---

**Ãšltima AtualizaÃ§Ã£o**: Novembro 2025
**VersÃ£o**: 4.0 (Projeto_Roupas_Versao4 - Notebook Kaggle)
